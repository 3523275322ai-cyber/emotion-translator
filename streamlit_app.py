import streamlit as st
import torch
import torch.nn as nn
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import librosa
import numpy as np
import requests
import tempfile
import os
from gtts import gTTS
import io
import base64

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="æƒ…æ„Ÿå¼ºåº¦ç¿»è¯‘å™¨",
    page_icon="ğŸ¯",
    layout="wide"
)

# æ ‡é¢˜å’Œä»‹ç»
st.title("ğŸ¯ æƒ…æ„Ÿå¼ºåº¦ç¿»è¯‘å™¨")
st.markdown("å°†è¯­éŸ³è½¬æ¢ä¸ºå¸¦æœ‰æƒ…æ„Ÿå¼ºåº¦çš„æ–‡å­—è¡¨è¾¾ - **24/7æ°¸ä¹…è¿è¡Œ**")

# åœ¨ä¾§è¾¹æ æ·»åŠ APIå¯†é’¥é…ç½®
with st.sidebar:
    st.header("ğŸ”‘ APIé…ç½®")
    
    # DeepSeek APIå¯†é’¥è¾“å…¥
    deepseek_key = st.text_input(
        "DeepSeek APIå¯†é’¥",
        type="password",
        placeholder="sk-39f4364f85c847ffac825438020bad68",
        help="è·å–å¯†é’¥ï¼šhttps://platform.deepseek.com/api_keys"
    )
    
    # ä¿å­˜å¯†é’¥åˆ°session state
    if deepseek_key:
        st.session_state.deepseek_api_key = deepseek_key
        st.success("âœ… APIå¯†é’¥å·²ä¿å­˜")
    elif 'deepseek_api_key' in st.session_state:
        # å¦‚æœsession stateä¸­å·²æœ‰å¯†é’¥ï¼Œæ˜¾ç¤ºå·²é…ç½®
        st.info("âœ… APIå¯†é’¥å·²é…ç½®")
    else:
        st.warning("âš ï¸ è¯·è¾“å…¥APIå¯†é’¥ä»¥è·å¾—æœ€ä½³æ•ˆæœ")
    
    st.markdown("---")
    st.markdown("### ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. åœ¨å·¦ä¾§è¾“å…¥DeepSeek APIå¯†é’¥
    2. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–å½•åˆ¶è¯­éŸ³
    3. ç‚¹å‡»åˆ†ææŒ‰é’®
    4. æŸ¥çœ‹æƒ…æ„Ÿç¿»è¯‘ç»“æœ
    """)

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼‰
@st.cache_resource
def load_models():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
    st.info(" åŠ è½½æ¨¡å‹ä¸­...")
    
    # è½¬å½•æ¨¡å‹
    processor = WhisperProcessor.from_pretrained("openai/whisper-small")
    model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
    
    # ç®€åŒ–æƒ…æ„Ÿå¼ºåº¦æ¨¡å‹
    class SimpleIntensityModel(nn.Module):
        def __init__(self, input_size=80, num_classes=6):
            super().__init__()
            self.classifier = nn.Sequential(
                nn.Linear(input_size, 128),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(128, num_classes)
            )
        def forward(self, x):
            return self.classifier(x)
    
    intensity_model = SimpleIntensityModel()
    
    st.success(" æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return processor, model, intensity_model

# åŠ è½½æ¨¡å‹
processor, model, intensity_model = load_models()

def get_deepseek_api_key():
    """è·å–DeepSeek APIå¯†é’¥ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„å¯†é’¥"""
    # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„å¯†é’¥
    if 'deepseek_api_key' in st.session_state and st.session_state.deepseek_api_key:
        return st.session_state.deepseek_api_key
    
    # å…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡
    env_key = os.getenv("DEEPSEEK_API_KEY")
    if env_key:
        return env_key
    
    return None

def transcribe_audio(audio_file):
    """è½¬å½•éŸ³é¢‘"""
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_file.read())
            tmp_file_path = tmp_file.name
        
        # åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(tmp_file_path, sr=16000)
        
        # æå–ç‰¹å¾
        input_features = processor(
            audio, 
            sampling_rate=sr, 
            return_tensors="pt"
        ).input_features
        
        # ç”Ÿæˆè½¬å½•
        with torch.no_grad():
            predicted_ids = model.generate(input_features)
        
        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_file_path)
        
        return transcription
        
    except Exception as e:
        return f"è½¬å½•å¤±è´¥: {str(e)}"

def predict_intensity_simple(audio_file):
    """ç®€å•æƒ…æ„Ÿå¼ºåº¦é¢„æµ‹"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_file.read())
            tmp_file_path = tmp_file.name
        
        audio, sr = librosa.load(tmp_file_path, sr=16000)
        
        # åŸºäºéŸ³é¢‘ç‰¹å¾ç®€å•åˆ¤æ–­å¼ºåº¦
        # 1. èƒ½é‡ç‰¹å¾
        rms = librosa.feature.rms(y=audio)
        avg_rms = np.mean(rms)
        
        # 2. é¢‘è°±ç‰¹å¾
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)
        avg_centroid = np.mean(spectral_centroids)
        
        # ç®€å•åŠ æƒè¯„åˆ†
        intensity_score = (avg_rms * 100 + avg_centroid / 100) / 2
        
        # æ˜ å°„åˆ°0-5
        if intensity_score < 0.1: intensity = 1
        elif intensity_score < 0.2: intensity = 2
        elif intensity_score < 0.4: intensity = 3
        elif intensity_score < 0.6: intensity = 4
        else: intensity = 5
        
        os.unlink(tmp_file_path)
        return intensity
        
    except Exception as e:
        st.error(f"å¼ºåº¦åˆ†æå¤±è´¥: {e}")
        return 3  # é»˜è®¤å€¼

def translate_with_emotion(text, intensity):
    """æƒ…æ„Ÿç¿»è¯‘"""
    api_key = get_deepseek_api_key()
    
    if not api_key:
        # å¤‡ç”¨ç¿»è¯‘ - ä½¿ç”¨æ›´æ™ºèƒ½çš„è§„åˆ™
        intensity_words = {
            1: "æœ‰ç‚¹",
            2: "æœ‰äº›", 
            3: "æ¯”è¾ƒ",
            4: "å¾ˆ",
            5: "éå¸¸"
        }
        
        word = intensity_words.get(intensity, "æœ‰äº›")
        
        # æ ¹æ®å¼ºåº¦è°ƒæ•´è¡¨è¾¾æ–¹å¼
        if intensity <= 1:
            return f"{text}"
        elif intensity <= 3:
            return f"æˆ‘ç°åœ¨{word}{text}ï¼Œè¯·å¸®å¸®æˆ‘"
        else:
            return f"æˆ‘ç°åœ¨{word}{text}ï¼è¯·å¸®å¸®æˆ‘ï¼"
    
    # DeepSeek APIè°ƒç”¨
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæƒ…æ„Ÿç¿»è¯‘å™¨ï¼Œä¸»è¦ç”¨äºåŒ»ç–—æŠ¤ç†åœºæ™¯ã€‚å°†ç”¨æˆ·ç®€å•çš„è¯è¯­è½¬æ¢æˆå¸¦æœ‰æƒ…æ„Ÿå¼ºåº¦çš„å®Œæ•´è¡¨è¾¾ã€‚
    
    è½¬æ¢è§„åˆ™ï¼š
    - å¼ºåº¦1-2ï¼šå¹³é™è¡¨è¾¾éœ€æ±‚
    - å¼ºåº¦3-4ï¼šä¸­ç­‰æ€¥åˆ‡çš„è¡¨è¾¾ï¼ŒåŠ ä¸Š"è¯·å¸®å¸®æˆ‘"
    - å¼ºåº¦5ï¼šéå¸¸æ€¥åˆ‡çš„è¡¨è¾¾ï¼ŒåŠ ä¸Šæ„Ÿå¹å·å’Œ"è¯·å¸®å¸®æˆ‘ï¼"
    
    ç›´æ¥è¾“å‡ºç¿»è¯‘åçš„å¥å­ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡Šã€‚"""
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ç”¨æˆ·è¯´ï¼š'{text}'ï¼Œæƒ…æ„Ÿå¼ºåº¦ï¼š{intensity}/5"}
    ]
    
    try:
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json={
                "model": "deepseek-chat",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 100
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
        
    except Exception as e:
        st.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {e}")
        # å¤‡ç”¨ç¿»è¯‘
        intensity_words = {
            1: "æœ‰ç‚¹",
            2: "æœ‰äº›", 
            3: "æ¯”è¾ƒ",
            4: "å¾ˆ",
            5: "éå¸¸"
        }
        word = intensity_words.get(intensity, "æœ‰äº›")
        return f"æˆ‘ç°åœ¨{word}{text}ï¼Œè¯·å¸®å¸®æˆ‘"

def text_to_speech_base64(text):
    """æ–‡æœ¬è½¬è¯­éŸ³ï¼Œè¿”å›base64"""
    try:
        tts = gTTS(text=text, lang="zh-cn")
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        audio_base64 = base64.b64encode(audio_buffer.read()).decode("utf-8")
        return f"data:audio/mp3;base64,{audio_base64}"
    except Exception as e:
        st.error(f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        return None

# ä¸»ç•Œé¢
tab1, tab2 = st.tabs(["ğŸ¤ éŸ³é¢‘åˆ†æ", "ğŸ’¡ ä½¿ç”¨è¯´æ˜"])

with tab1:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ä¸Šä¼ éŸ³é¢‘")
        
        # æ–‡ä»¶ä¸Šä¼ 
        audio_file = st.file_uploader(
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            type=["wav", "mp3", "m4a", "ogg"],
            help="æ”¯æŒ WAV, MP3, M4A, OGG æ ¼å¼"
        )
        
        # å½•éŸ³åŠŸèƒ½
        st.markdown("### æˆ–è€…å½•åˆ¶è¯­éŸ³")
        recorded_audio = st.audio_input("ç‚¹å‡»éº¦å…‹é£å¼€å§‹å½•éŸ³")
        
        # ç¡®å®šä½¿ç”¨çš„éŸ³é¢‘æº
        final_audio_file = audio_file or recorded_audio
        
        if final_audio_file is not None:
            # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            st.audio(final_audio_file, format="audio/wav")
            file_source = "ä¸Šä¼ æ–‡ä»¶" if audio_file else "å½•éŸ³"
            st.info(f"ğŸ“ {file_source}å°±ç»ª")
            
            # åˆ†ææŒ‰é’®
            if st.button(" å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
                with st.spinner("åˆ†æä¸­...è¯·ç¨å€™"):
                    # è½¬å½•
                    transcription = transcribe_audio(final_audio_file)
                    
                    # æƒ…æ„Ÿå¼ºåº¦
                    intensity = predict_intensity_simple(final_audio_file)
                    
                    # æƒ…æ„Ÿç¿»è¯‘
                    translated_text = translate_with_emotion(transcription, intensity)
                    
                    # ç”Ÿæˆè¯­éŸ³
                    audio_url = text_to_speech_base64(translated_text)
                
                # æ˜¾ç¤ºç»“æœ
                st.success(" åˆ†æå®Œæˆï¼")
                
                st.subheader(" åˆ†æç»“æœ")
                
                col_a, col_b = st.columns(2)
                
                with col_a:
                    st.metric("åŸå§‹è½¬å½•", transcription)
                    
                    # æ˜¾ç¤ºæƒ…æ„Ÿå¼ºåº¦è¿›åº¦æ¡
                    st.markdown("**æƒ…æ„Ÿå¼ºåº¦**")
                    st.progress(intensity/5)
                    st.write(f"å¼ºåº¦å€¼: {intensity}/5")
                
                with col_b:
                    st.text_area("æƒ…æ„Ÿç¿»è¯‘", translated_text, height=100, key="translated_text")
                
                # è¯­éŸ³æ’­æ”¾
                if audio_url:
                    st.subheader("ğŸ”Š è¯­éŸ³è¾“å‡º")
                    st.audio(audio_url, format="audio/mp3")
                    
                    # ä¸‹è½½æŒ‰é’®
                    audio_data = base64.b64decode(audio_url.split(",")[1])
                    st.download_button(
                        " ä¸‹è½½è¯­éŸ³",
                        data=audio_data,
                        file_name="æƒ…æ„Ÿç¿»è¯‘.mp3",
                        mime="audio/mp3",
                        use_container_width=True
                    )

    with col2:
        st.subheader("å®æ—¶çŠ¶æ€")
        
        # æ˜¾ç¤ºé…ç½®çŠ¶æ€
        st.subheader("âš™ï¸ é…ç½®çŠ¶æ€")
        
        api_key = get_deepseek_api_key()
        if api_key:
            st.success("âœ… DeepSeek API å·²é…ç½®")
            st.info("ğŸ’¡ ä½¿ç”¨AIå¢å¼ºçš„æƒ…æ„Ÿç¿»è¯‘")
        else:
            st.warning("âš ï¸ DeepSeek API æœªé…ç½®")
            st.info("ğŸ’¡ ä½¿ç”¨åŸºç¡€è§„åˆ™çš„æƒ…æ„Ÿç¿»è¯‘")
            
        if final_audio_file is None:
            st.info("ğŸ‘† è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–å½•åˆ¶è¯­éŸ³åå¼€å§‹åˆ†æ")
        else:
            st.success(" éŸ³é¢‘æ–‡ä»¶å·²å°±ç»ª")
            
        # æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'analysis_count' not in st.session_state:
            st.session_state.analysis_count = 0
            
        if final_audio_file and st.button:
            st.session_state.analysis_count += 1
            
        st.metric("åˆ†ææ¬¡æ•°", st.session_state.analysis_count)

with tab2:
    st.subheader("ä½¿ç”¨è¯´æ˜")
    
    st.markdown("""
    ###  åŠŸèƒ½è¯´æ˜
    å°†ç”¨æˆ·çš„è¯­éŸ³è½¬æ¢æˆå¸¦æœ‰æƒ…æ„Ÿå¼ºåº¦çš„æ–‡å­—è¡¨è¾¾ï¼Œä¸»è¦ç”¨äºåŒ»ç–—æŠ¤ç†åœºæ™¯ã€‚
    
    ###  ä½¿ç”¨ç¤ºä¾‹
    | ç”¨æˆ·è¾“å…¥ | æƒ…æ„Ÿå¼ºåº¦ | è¾“å‡ºç»“æœ |
    |---------|----------|----------|
    | "æˆ‘æƒ³å–æ°´" | å¼ºåº¦2 | "æˆ‘ç°åœ¨æœ‰ç‚¹æƒ³å–æ°´ï¼Œè¯·å¸®å¸®æˆ‘" |
    | "æˆ‘æƒ³å–æ°´" | å¼ºåº¦4 | "æˆ‘ç°åœ¨å¾ˆæƒ³å–æ°´ï¼è¯·å¸®å¸®æˆ‘ï¼" |
    | "æˆ‘æœ‰ç‚¹å†·" | å¼ºåº¦3 | "æˆ‘ç°åœ¨æ¯”è¾ƒå†·ï¼Œè¯·å¸®å¸®æˆ‘" |
    
    ###  æƒ…æ„Ÿå¼ºåº¦è¯´æ˜
    - **å¼ºåº¦1**: å¹³é™è¡¨è¾¾
    - **å¼ºåº¦2-3**: ä¸­ç­‰æ€¥åˆ‡  
    - **å¼ºåº¦4-5**: éå¸¸æ€¥åˆ‡
    
    ###  APIé…ç½®è¯´æ˜
    1. è®¿é—® [DeepSeekå¹³å°](https://platform.deepseek.com/api_keys)
    2. æ³¨å†Œè´¦å·å¹¶è·å–APIå¯†é’¥
    3. åœ¨å·¦ä¾§è¾¹æ è¾“å…¥å¯†é’¥
    4. äº«å—AIå¢å¼ºçš„æƒ…æ„Ÿç¿»è¯‘
    
    ###  æŠ€æœ¯æ¶æ„
    - **è¯­éŸ³è½¬å½•**: OpenAI Whisper
    - **æƒ…æ„Ÿåˆ†æ**: è‡ªå®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹
    - **æ–‡æœ¬ç”Ÿæˆ**: DeepSeek API
    - **è¯­éŸ³åˆæˆ**: Google TTS
    """)

# é¡µè„š
st.markdown("---")
st.markdown(" æƒ…æ„Ÿå¼ºåº¦ç¿»è¯‘å™¨ | 24/7æ°¸ä¹…è¿è¡Œ | æ”¯æŒç›´æ¥é…ç½®APIå¯†é’¥")
